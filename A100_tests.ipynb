{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "830f2d45",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659a01a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia-smi -i 0,1 --query-gpu=gpu_bus_id,power.draw,utilization.gpu,memory.used --format=csv,nounits --loop-ms=1000 > ./gpu_stats/tf32_2GPUs.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b991b856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb972ce",
   "metadata": {},
   "source": [
    "Test:\n",
    "- Baseline (tf-32)\n",
    "- Precision\n",
    "    - tf32 (default)\n",
    "    - float32\n",
    "    - mixed\n",
    "    - bfloat\n",
    "- Batch size\n",
    "    - 64 (default)\n",
    "    - 96 (from paper)\n",
    "    - 128\n",
    "    - max (power of 2)\n",
    "    - max (non power of 2) \n",
    "    - Test with tf32 and fp32\n",
    "- different number of GPUs\n",
    "    - 1\n",
    "    - 2\n",
    "    - 4\n",
    "    - 8\n",
    "    - 16 (2 nodes)\n",
    "- diferent GPUs (repeat tests)\n",
    "    - A100\n",
    "    - V100\n",
    "    - A10\n",
    "    - best of all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ae0c2b",
   "metadata": {},
   "source": [
    "# Total model flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a27b57c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 2048)]       0           []                               \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 6144)]       0           []                               \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)       (None, 8192)         0           ['input_7[0][0]',                \n",
      "                                                                  'input_8[0][0]']                \n",
      "                                                                                                  \n",
      " pixel_norm_layer_13 (Pixel_nor  (None, 8192)        0           ['tf.concat_1[1][0]']            \n",
      " m_layer)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_1 (TFOpLambda)      (None, 512, 4, 4)    0           ['pixel_norm_layer_13[1][0]']    \n",
      "                                                                                                  \n",
      " 4x4_Dense_bias_PN (Bias)       (None, 512, 4, 4)    512         ['tf.reshape_1[1][0]']           \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 512, 4, 4)    0           ['4x4_Dense_bias_PN[1][0]']      \n",
      "                                                                                                  \n",
      " pixel_norm_layer_14 (Pixel_nor  (None, 512, 4, 4)   0           ['leaky_re_lu_12[1][0]']         \n",
      " m_layer)                                                                                         \n",
      "                                                                                                  \n",
      " 4x4/Conv (Conv2D)              (None, 512, 4, 4)    2359296     ['pixel_norm_layer_14[1][0]']    \n",
      "                                                                                                  \n",
      " weight_scale_layer_17 (WeightS  (None, 512, 4, 4)   0           ['4x4/Conv[1][0]']               \n",
      " caleLayer)                                                                                       \n",
      "                                                                                                  \n",
      " 4x4/Conv_bias (Bias)           (None, 512, 4, 4)    512         ['weight_scale_layer_17[1][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 512, 4, 4)    0           ['4x4/Conv_bias[1][0]']          \n",
      "                                                                                                  \n",
      " pixel_norm_layer_15 (Pixel_nor  (None, 512, 4, 4)   0           ['leaky_re_lu_13[1][0]']         \n",
      " m_layer)                                                                                         \n",
      "                                                                                                  \n",
      " up_sampling2d_10 (UpSampling2D  (None, 512, 8, 8)   0           ['pixel_norm_layer_15[1][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " 8x8/Conv0 (Conv2D)             (None, 512, 8, 8)    2359296     ['up_sampling2d_10[1][0]']       \n",
      "                                                                                                  \n",
      " weight_scale_layer_19 (WeightS  (None, 512, 8, 8)   0           ['8x8/Conv0[1][0]']              \n",
      " caleLayer)                                                                                       \n",
      "                                                                                                  \n",
      " 8x8/Conv0_bias (Bias)          (None, 512, 8, 8)    512         ['weight_scale_layer_19[1][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)     (None, 512, 8, 8)    0           ['8x8/Conv0_bias[1][0]']         \n",
      "                                                                                                  \n",
      " pixel_norm_layer_16 (Pixel_nor  (None, 512, 8, 8)   0           ['leaky_re_lu_14[1][0]']         \n",
      " m_layer)                                                                                         \n",
      "                                                                                                  \n",
      " 8x8/Conv1 (Conv2D)             (None, 512, 8, 8)    2359296     ['pixel_norm_layer_16[1][0]']    \n",
      "                                                                                                  \n",
      " weight_scale_layer_20 (WeightS  (None, 512, 8, 8)   0           ['8x8/Conv1[1][0]']              \n",
      " caleLayer)                                                                                       \n",
      "                                                                                                  \n",
      " 8x8/Conv1_bias (Bias)          (None, 512, 8, 8)    512         ['weight_scale_layer_20[1][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_15 (LeakyReLU)     (None, 512, 8, 8)    0           ['8x8/Conv1_bias[1][0]']         \n",
      "                                                                                                  \n",
      " pixel_norm_layer_17 (Pixel_nor  (None, 512, 8, 8)   0           ['leaky_re_lu_15[1][0]']         \n",
      " m_layer)                                                                                         \n",
      "                                                                                                  \n",
      " up_sampling2d_12 (UpSampling2D  (None, 512, 16, 16)  0          ['pixel_norm_layer_17[1][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " 16x16/Conv0 (Conv2D)           (None, 512, 16, 16)  2359296     ['up_sampling2d_12[1][0]']       \n",
      "                                                                                                  \n",
      " weight_scale_layer_22 (WeightS  (None, 512, 16, 16)  0          ['16x16/Conv0[1][0]']            \n",
      " caleLayer)                                                                                       \n",
      "                                                                                                  \n",
      " 16x16/Conv0_bias (Bias)        (None, 512, 16, 16)  512         ['weight_scale_layer_22[1][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_16 (LeakyReLU)     (None, 512, 16, 16)  0           ['16x16/Conv0_bias[1][0]']       \n",
      "                                                                                                  \n",
      " pixel_norm_layer_18 (Pixel_nor  (None, 512, 16, 16)  0          ['leaky_re_lu_16[1][0]']         \n",
      " m_layer)                                                                                         \n",
      "                                                                                                  \n",
      " 16x16/Conv1 (Conv2D)           (None, 512, 16, 16)  2359296     ['pixel_norm_layer_18[1][0]']    \n",
      "                                                                                                  \n",
      " weight_scale_layer_23 (WeightS  (None, 512, 16, 16)  0          ['16x16/Conv1[1][0]']            \n",
      " caleLayer)                                                                                       \n",
      "                                                                                                  \n",
      " 16x16/Conv1_bias (Bias)        (None, 512, 16, 16)  512         ['weight_scale_layer_23[1][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_17 (LeakyReLU)     (None, 512, 16, 16)  0           ['16x16/Conv1_bias[1][0]']       \n",
      "                                                                                                  \n",
      " pixel_norm_layer_19 (Pixel_nor  (None, 512, 16, 16)  0          ['leaky_re_lu_17[1][0]']         \n",
      " m_layer)                                                                                         \n",
      "                                                                                                  \n",
      " up_sampling2d_14 (UpSampling2D  (None, 512, 32, 32)  0          ['pixel_norm_layer_19[1][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " 32x32/Conv0 (Conv2D)           (None, 512, 32, 32)  2359296     ['up_sampling2d_14[1][0]']       \n",
      "                                                                                                  \n",
      " weight_scale_layer_25 (WeightS  (None, 512, 32, 32)  0          ['32x32/Conv0[1][0]']            \n",
      " caleLayer)                                                                                       \n",
      "                                                                                                  \n",
      " 32x32/Conv0_bias (Bias)        (None, 512, 32, 32)  512         ['weight_scale_layer_25[1][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_18 (LeakyReLU)     (None, 512, 32, 32)  0           ['32x32/Conv0_bias[1][0]']       \n",
      "                                                                                                  \n",
      " pixel_norm_layer_20 (Pixel_nor  (None, 512, 32, 32)  0          ['leaky_re_lu_18[1][0]']         \n",
      " m_layer)                                                                                         \n",
      "                                                                                                  \n",
      " 32x32/Conv1 (Conv2D)           (None, 512, 32, 32)  2359296     ['pixel_norm_layer_20[1][0]']    \n",
      "                                                                                                  \n",
      " weight_scale_layer_26 (WeightS  (None, 512, 32, 32)  0          ['32x32/Conv1[1][0]']            \n",
      " caleLayer)                                                                                       \n",
      "                                                                                                  \n",
      " 32x32/Conv1_bias (Bias)        (None, 512, 32, 32)  512         ['weight_scale_layer_26[1][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_19 (LeakyReLU)     (None, 512, 32, 32)  0           ['32x32/Conv1_bias[1][0]']       \n",
      "                                                                                                  \n",
      " pixel_norm_layer_21 (Pixel_nor  (None, 512, 32, 32)  0          ['leaky_re_lu_19[1][0]']         \n",
      " m_layer)                                                                                         \n",
      "                                                                                                  \n",
      " up_sampling2d_16 (UpSampling2D  (None, 512, 64, 64)  0          ['pixel_norm_layer_21[1][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " 64x64/Conv0 (Conv2D)           (None, 256, 64, 64)  1179648     ['up_sampling2d_16[1][0]']       \n",
      "                                                                                                  \n",
      " weight_scale_layer_28 (WeightS  (None, 256, 64, 64)  0          ['64x64/Conv0[1][0]']            \n",
      " caleLayer)                                                                                       \n",
      "                                                                                                  \n",
      " 64x64/Conv0_bias (Bias)        (None, 256, 64, 64)  256         ['weight_scale_layer_28[1][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_20 (LeakyReLU)     (None, 256, 64, 64)  0           ['64x64/Conv0_bias[1][0]']       \n",
      "                                                                                                  \n",
      " pixel_norm_layer_22 (Pixel_nor  (None, 256, 64, 64)  0          ['leaky_re_lu_20[1][0]']         \n",
      " m_layer)                                                                                         \n",
      "                                                                                                  \n",
      " 64x64/Conv1 (Conv2D)           (None, 256, 64, 64)  589824      ['pixel_norm_layer_22[1][0]']    \n",
      "                                                                                                  \n",
      " weight_scale_layer_29 (WeightS  (None, 256, 64, 64)  0          ['64x64/Conv1[1][0]']            \n",
      " caleLayer)                                                                                       \n",
      "                                                                                                  \n",
      " 64x64/Conv1_bias (Bias)        (None, 256, 64, 64)  256         ['weight_scale_layer_29[1][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_21 (LeakyReLU)     (None, 256, 64, 64)  0           ['64x64/Conv1_bias[1][0]']       \n",
      "                                                                                                  \n",
      " pixel_norm_layer_23 (Pixel_nor  (None, 256, 64, 64)  0          ['leaky_re_lu_21[1][0]']         \n",
      " m_layer)                                                                                         \n",
      "                                                                                                  \n",
      " up_sampling2d_18 (UpSampling2D  (None, 256, 128, 12  0          ['pixel_norm_layer_23[1][0]']    \n",
      " )                              8)                                                                \n",
      "                                                                                                  \n",
      " 128x128/Conv0 (Conv2D)         (None, 128, 128, 12  294912      ['up_sampling2d_18[1][0]']       \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " weight_scale_layer_31 (WeightS  (None, 128, 128, 12  0          ['128x128/Conv0[1][0]']          \n",
      " caleLayer)                     8)                                                                \n",
      "                                                                                                  \n",
      " 4x4/ToRGB_lod (Conv2D)         (None, 1, 4, 4)      512         ['pixel_norm_layer_15[1][0]']    \n",
      "                                                                                                  \n",
      " 128x128/Conv0_bias (Bias)      (None, 128, 128, 12  128         ['weight_scale_layer_31[1][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " 8x8/ToRGB_lod (Conv2D)         (None, 1, 8, 8)      512         ['pixel_norm_layer_17[1][0]']    \n",
      "                                                                                                  \n",
      " weight_scale_layer_18 (WeightS  (None, 1, 4, 4)     0           ['4x4/ToRGB_lod[1][0]']          \n",
      " caleLayer)                                                                                       \n",
      "                                                                                                  \n",
      " leaky_re_lu_22 (LeakyReLU)     (None, 128, 128, 12  0           ['128x128/Conv0_bias[1][0]']     \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " weight_scale_layer_21 (WeightS  (None, 1, 8, 8)     0           ['8x8/ToRGB_lod[1][0]']          \n",
      " caleLayer)                                                                                       \n",
      "                                                                                                  \n",
      " 4x4/ToRGB_lod_bias (Bias)      (None, 1, 4, 4)      1           ['weight_scale_layer_18[1][0]']  \n",
      "                                                                                                  \n",
      " input_9 (InputLayer)           [(1,)]               0           []                               \n",
      "                                                                                                  \n",
      " pixel_norm_layer_24 (Pixel_nor  (None, 128, 128, 12  0          ['leaky_re_lu_22[1][0]']         \n",
      " m_layer)                       8)                                                                \n",
      "                                                                                                  \n",
      " 16x16/ToRGB_lod (Conv2D)       (None, 1, 16, 16)    512         ['pixel_norm_layer_19[1][0]']    \n",
      "                                                                                                  \n",
      " 8x8/ToRGB_lod_bias (Bias)      (None, 1, 8, 8)      1           ['weight_scale_layer_21[1][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_11 (UpSampling2D  (None, 1, 8, 8)     0           ['4x4/ToRGB_lod_bias[1][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.subtract_5 (TFOpLambda  (1,)                0           ['input_9[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " 128x128/Conv1 (Conv2D)         (None, 128, 128, 12  147456      ['pixel_norm_layer_24[1][0]']    \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " weight_scale_layer_24 (WeightS  (None, 1, 16, 16)   0           ['16x16/ToRGB_lod[1][0]']        \n",
      " caleLayer)                                                                                       \n",
      "                                                                                                  \n",
      " lerp_clip_layer_5 (Lerp_clip_l  (None, 1, 8, 8)     0           ['8x8/ToRGB_lod_bias[1][0]',     \n",
      " ayer)                                                            'up_sampling2d_11[1][0]',       \n",
      "                                                                  'tf.math.subtract_5[1][0]']     \n",
      "                                                                                                  \n",
      " weight_scale_layer_32 (WeightS  (None, 128, 128, 12  0          ['128x128/Conv1[1][0]']          \n",
      " caleLayer)                     8)                                                                \n",
      "                                                                                                  \n",
      " 32x32/ToRGB_lod (Conv2D)       (None, 1, 32, 32)    512         ['pixel_norm_layer_21[1][0]']    \n",
      "                                                                                                  \n",
      " 16x16/ToRGB_lod_bias (Bias)    (None, 1, 16, 16)    1           ['weight_scale_layer_24[1][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_13 (UpSampling2D  (None, 1, 16, 16)   0           ['lerp_clip_layer_5[1][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.subtract_6 (TFOpLambda  (1,)                0           ['input_9[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " 128x128/Conv1_bias (Bias)      (None, 128, 128, 12  128         ['weight_scale_layer_32[1][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " weight_scale_layer_27 (WeightS  (None, 1, 32, 32)   0           ['32x32/ToRGB_lod[1][0]']        \n",
      " caleLayer)                                                                                       \n",
      "                                                                                                  \n",
      " lerp_clip_layer_6 (Lerp_clip_l  (None, 1, 16, 16)   0           ['16x16/ToRGB_lod_bias[1][0]',   \n",
      " ayer)                                                            'up_sampling2d_13[1][0]',       \n",
      "                                                                  'tf.math.subtract_6[1][0]']     \n",
      "                                                                                                  \n",
      " leaky_re_lu_23 (LeakyReLU)     (None, 128, 128, 12  0           ['128x128/Conv1_bias[1][0]']     \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " 64x64/ToRGB_lod (Conv2D)       (None, 1, 64, 64)    256         ['pixel_norm_layer_23[1][0]']    \n",
      "                                                                                                  \n",
      " 32x32/ToRGB_lod_bias (Bias)    (None, 1, 32, 32)    1           ['weight_scale_layer_27[1][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_15 (UpSampling2D  (None, 1, 32, 32)   0           ['lerp_clip_layer_6[1][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.subtract_7 (TFOpLambda  (1,)                0           ['input_9[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pixel_norm_layer_25 (Pixel_nor  (None, 128, 128, 12  0          ['leaky_re_lu_23[1][0]']         \n",
      " m_layer)                       8)                                                                \n",
      "                                                                                                  \n",
      " weight_scale_layer_30 (WeightS  (None, 1, 64, 64)   0           ['64x64/ToRGB_lod[1][0]']        \n",
      " caleLayer)                                                                                       \n",
      "                                                                                                  \n",
      " lerp_clip_layer_7 (Lerp_clip_l  (None, 1, 32, 32)   0           ['32x32/ToRGB_lod_bias[1][0]',   \n",
      " ayer)                                                            'up_sampling2d_15[1][0]',       \n",
      "                                                                  'tf.math.subtract_7[1][0]']     \n",
      "                                                                                                  \n",
      " 128x128/ToRGB_lod (Conv2D)     (None, 1, 128, 128)  128         ['pixel_norm_layer_25[1][0]']    \n",
      "                                                                                                  \n",
      " 64x64/ToRGB_lod_bias (Bias)    (None, 1, 64, 64)    1           ['weight_scale_layer_30[1][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_17 (UpSampling2D  (None, 1, 64, 64)   0           ['lerp_clip_layer_7[1][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.subtract_8 (TFOpLambda  (1,)                0           ['input_9[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " weight_scale_layer_33 (WeightS  (None, 1, 128, 128)  0          ['128x128/ToRGB_lod[1][0]']      \n",
      " caleLayer)                                                                                       \n",
      "                                                                                                  \n",
      " lerp_clip_layer_8 (Lerp_clip_l  (None, 1, 64, 64)   0           ['64x64/ToRGB_lod_bias[1][0]',   \n",
      " ayer)                                                            'up_sampling2d_17[1][0]',       \n",
      "                                                                  'tf.math.subtract_8[1][0]']     \n",
      "                                                                                                  \n",
      " 128x128/ToRGB_lod_bias (Bias)  (None, 1, 128, 128)  1           ['weight_scale_layer_33[1][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_19 (UpSampling2D  (None, 1, 128, 128)  0          ['lerp_clip_layer_8[1][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.subtract_9 (TFOpLambda  (1,)                0           ['input_9[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " lerp_clip_layer_9 (Lerp_clip_l  (None, 1, 128, 128)  0          ['128x128/ToRGB_lod_bias[1][0]', \n",
      " ayer)                                                            'up_sampling2d_19[1][0]',       \n",
      "                                                                  'tf.math.subtract_9[1][0]']     \n",
      "                                                                                                  \n",
      " tf.identity_1 (TFOpLambda)     (None, 1, 128, 128)  0           ['lerp_clip_layer_9[1][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18,734,214\n",
      "Trainable params: 18,734,214\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 07:58:37.316125: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 8\n",
      "2023-04-24 07:58:37.316296: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-04-24 07:58:37.367878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38214 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "2023-04-24 07:58:37.369417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38214 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:15:00.0, compute capability: 8.0\n",
      "2023-04-24 07:58:37.370950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38214 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:51:00.0, compute capability: 8.0\n",
      "2023-04-24 07:58:37.372496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38214 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:54:00.0, compute capability: 8.0\n",
      "2023-04-24 07:58:37.374034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 38214 MB memory:  -> device: 4, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:8d:00.0, compute capability: 8.0\n",
      "2023-04-24 07:58:37.375580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 38214 MB memory:  -> device: 5, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:92:00.0, compute capability: 8.0\n",
      "2023-04-24 07:58:37.377115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 38214 MB memory:  -> device: 6, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:d6:00.0, compute capability: 8.0\n",
      "2023-04-24 07:58:37.378661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 38214 MB memory:  -> device: 7, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:da:00.0, compute capability: 8.0\n",
      "2023-04-24 07:58:37.419211: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.703ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:62: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "Generator FLOPS =  20894345882.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from networks2 import generator\n",
    "\n",
    "def get_flops(model, model_inputs) -> float:\n",
    "        \"\"\"\n",
    "        Calculate FLOPS [GFLOPs] for a tf.keras.Model or tf.keras.Sequential model\n",
    "        in inference mode. It uses tf.compat.v1.profiler under the hood.\n",
    "        \"\"\"\n",
    "        # if not hasattr(model, \"model\"):\n",
    "        #     raise wandb.Error(\"self.model must be set before using this method.\")\n",
    "\n",
    "        if not isinstance(\n",
    "            model, (tf.keras.models.Sequential, tf.keras.models.Model)\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                \"Calculating FLOPS is only supported for \"\n",
    "                \"`tf.keras.Model` and `tf.keras.Sequential` instances.\"\n",
    "            )\n",
    "\n",
    "        from tensorflow.python.framework.convert_to_constants import (\n",
    "            convert_variables_to_constants_v2_as_graph,\n",
    "        )\n",
    "\n",
    "        # Compute FLOPs for one sample\n",
    "        batch_size = 1\n",
    "        inputs = [\n",
    "            tf.TensorSpec([batch_size] + inp.shape[1:], inp.dtype)\n",
    "            for inp in model_inputs\n",
    "        ]\n",
    "\n",
    "        # convert tf.keras model into frozen graph to count FLOPs about operations used at inference\n",
    "        real_model = tf.function(model).get_concrete_function(inputs)\n",
    "        frozen_func, _ = convert_variables_to_constants_v2_as_graph(real_model)\n",
    "\n",
    "        # Calculate FLOPs with tf.profiler\n",
    "        run_meta = tf.compat.v1.RunMetadata()\n",
    "        opts = (\n",
    "            tf.compat.v1.profiler.ProfileOptionBuilder(\n",
    "                tf.compat.v1.profiler.ProfileOptionBuilder().float_operation()\n",
    "            )\n",
    "            .with_empty_output()\n",
    "            .build()\n",
    "        )\n",
    "\n",
    "        flops = tf.compat.v1.profiler.profile(\n",
    "            graph=frozen_func.graph, run_meta=run_meta, cmd=\"scope\", options=opts\n",
    "        )\n",
    "\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "\n",
    "        # convert to GFLOPs\n",
    "        return (flops.total_float_ops)/2\n",
    "    \n",
    "def forward_backward():\n",
    "    \n",
    "    for_flop = 0\n",
    "    total_flop = 0\n",
    "    session = tf.compat.v1.Session()\n",
    "    graph = tf.compat.v1.get_default_graph()\n",
    "    \n",
    "    with graph.as_default():\n",
    "        with session.as_default():\n",
    "\n",
    "            #model = tf.keras.applications.ResNet50() # change your model here\n",
    "\n",
    "            model = generator_model(256, dformat=\"channels_first\")\n",
    "            \n",
    "            x = tf.constant(np.random.randn(1, 256))\n",
    "            \n",
    "            outputTensor = model([x]) \n",
    "            listOfVariableTensors = model.trainable_weights\n",
    "            gradients = tf.gradients(outputTensor, listOfVariableTensors)\n",
    "\n",
    "            run_meta = tf.compat.v1.RunMetadata()\n",
    "            opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "\n",
    "            # We use the Keras session graph in the call to the profiler.\n",
    "            flops = tf.compat.v1.profiler.profile(graph=graph,\n",
    "                                                  run_meta=run_meta, cmd='op', options=opts)\n",
    "\n",
    "            total_flop = flops.total_float_ops\n",
    "            print(total_flop)\n",
    "\n",
    "    return for_flop, total_flop\n",
    "    \n",
    "    \n",
    "    \n",
    "#Usage\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    #image_model = tf.keras.applications.EfficientNetB0(include_top=False, weights=None)\n",
    "    \n",
    "    #x = tf.constant(np.random.randn(1, 256))\n",
    "    noise = tf.constant(np.random.randn(1, 2048))\n",
    "    latent_noise = tf.constant(np.random.randn(1, 6144))\n",
    "    lod_in = tf.constant(0)\n",
    "    #y = tf.constant(np.random.randn(1, 1, 51 , 51, 25))\n",
    "    \n",
    "    #print(x.shape)\n",
    "    \n",
    "    model_g = generator(num_channels=1) #Model(inputs=[latent], outputs=[fake_image], name='Generator')\n",
    "    #model_d = discriminator_model(dformat=\"channels_first\")\n",
    "    #model.summary()\n",
    "    print('Generator FLOPS = ', get_flops(model_g,[noise, latent_noise, lod_in]))\n",
    "    #print('Discriminator FLOPS = ', get_flops(model_d,[y]))\n",
    "    \n",
    "    #forward_backward()\n",
    "    \n",
    "    #print(get_flops(model, [x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db315241",
   "metadata": {},
   "source": [
    "# Theoretical calculation of floops\n",
    "\n",
    "$ ConvFlops = 2 * NumberKernel * ShapeKernel * OutputShape $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1988ec7e",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9653f3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "/home/datascience/floods/\n",
      "/home/datascience/floods/\n",
      "True\n",
      "32\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of devices: 1\n",
      "['/home/datascience/floods/floods-r02.tfrecords', '/home/datascience/floods/floods-r03.tfrecords', '/home/datascience/floods/floods-r04.tfrecords', '/home/datascience/floods/floods-r05.tfrecords', '/home/datascience/floods/floods-r06.tfrecords', '/home/datascience/floods/floods-r07.tfrecords', '/home/datascience/floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 256, 2: 128, 1: 64, 0: 32}\n",
      "Dataset Read\n",
      "['/home/datascience/floods/floods-r02.tfrecords', '/home/datascience/floods/floods-r03.tfrecords', '/home/datascience/floods/floods-r04.tfrecords', '/home/datascience/floods/floods-r05.tfrecords', '/home/datascience/floods/floods-r06.tfrecords', '/home/datascience/floods/floods-r07.tfrecords', '/home/datascience/floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 256, 2: 128, 1: 64, 0: 32}\n",
      "Dataset Read\n",
      "['/home/datascience//floods/floods-r02.tfrecords', '/home/datascience//floods/floods-r03.tfrecords', '/home/datascience//floods/floods-r04.tfrecords', '/home/datascience//floods/floods-r05.tfrecords', '/home/datascience//floods/floods-r06.tfrecords', '/home/datascience//floods/floods-r07.tfrecords', '/home/datascience//floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 64, 2: 64, 1: 32, 0: 16}\n",
      "Dataset Read\n",
      "<BatchDataset element_spec=TensorSpec(shape=(None, 1, None, None), dtype=tf.uint8, name=None)>\n",
      "0\n",
      "Increase Resoltion from -1 to 256\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "256\n",
      "Changing optimizer\n",
      "False\n",
      "Changing optimizer\n",
      "False\n",
      "Finished changing resolution\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  27348714298436\n",
      "Average per batch was:  5.651037740707397\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "from train import train_cycle\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "train_cycle(datapath='/home/datascience/',outpath='./',init_res=256,max_res=256,change_model=True,minibatch_base=32,batch_size=32,profiling=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83556399",
   "metadata": {},
   "source": [
    "# Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cb10c1",
   "metadata": {},
   "source": [
    "## Float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52400a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "/home/datascience/floods/\n",
      "/home/datascience/floods/\n",
      "False\n",
      "32\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of devices: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 22:11:53.754614: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-25 22:11:54.419532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38214 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "['/home/datascience/floods/floods-r02.tfrecords', '/home/datascience/floods/floods-r03.tfrecords', '/home/datascience/floods/floods-r04.tfrecords', '/home/datascience/floods/floods-r05.tfrecords', '/home/datascience/floods/floods-r06.tfrecords', '/home/datascience/floods/floods-r07.tfrecords', '/home/datascience/floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 256, 2: 128, 1: 64, 0: 32}\n",
      "Dataset Read\n",
      "['/home/datascience/floods/floods-r02.tfrecords', '/home/datascience/floods/floods-r03.tfrecords', '/home/datascience/floods/floods-r04.tfrecords', '/home/datascience/floods/floods-r05.tfrecords', '/home/datascience/floods/floods-r06.tfrecords', '/home/datascience/floods/floods-r07.tfrecords', '/home/datascience/floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 256, 2: 128, 1: 64, 0: 32}\n",
      "Dataset Read\n",
      "['/home/datascience//floods/floods-r02.tfrecords', '/home/datascience//floods/floods-r03.tfrecords', '/home/datascience//floods/floods-r04.tfrecords', '/home/datascience//floods/floods-r05.tfrecords', '/home/datascience//floods/floods-r06.tfrecords', '/home/datascience//floods/floods-r07.tfrecords', '/home/datascience//floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 64, 2: 64, 1: 32, 0: 16}\n",
      "Dataset Read\n",
      "<BatchDataset element_spec=TensorSpec(shape=(None, 1, None, None), dtype=tf.uint8, name=None)>\n",
      "0\n",
      "Increase Resoltion from -1 to 256\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "256\n",
      "Changing optimizer\n",
      "False\n",
      "Changing optimizer\n",
      "False\n",
      "Finished changing resolution\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 22:12:30.598250: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8401\n",
      "2023-04-25 22:12:32.055810: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-04-25 22:12:32.328435: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: ptxas exited with non-zero error code 32512, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  27348714298436\n",
      "Average per batch was:  8.767802190780639\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "from train import train_cycle\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "train_cycle(datapath='/home/datascience/',outpath='./',init_res=256,max_res=256,change_model=True,minibatch_base=32,batch_size=32,profiling=True,use_tf32=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe19e7a",
   "metadata": {},
   "source": [
    "## Mixed Float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ca4187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "/home/datascience/floods/\n",
      "/home/datascience/floods/\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA A100-SXM4-40GB, compute capability 8.0\n",
      "False\n",
      "32\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of devices: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 22:14:04.760360: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-25 22:14:05.425752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38214 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "['/home/datascience/floods/floods-r02.tfrecords', '/home/datascience/floods/floods-r03.tfrecords', '/home/datascience/floods/floods-r04.tfrecords', '/home/datascience/floods/floods-r05.tfrecords', '/home/datascience/floods/floods-r06.tfrecords', '/home/datascience/floods/floods-r07.tfrecords', '/home/datascience/floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 256, 2: 128, 1: 64, 0: 32}\n",
      "Dataset Read\n",
      "['/home/datascience/floods/floods-r02.tfrecords', '/home/datascience/floods/floods-r03.tfrecords', '/home/datascience/floods/floods-r04.tfrecords', '/home/datascience/floods/floods-r05.tfrecords', '/home/datascience/floods/floods-r06.tfrecords', '/home/datascience/floods/floods-r07.tfrecords', '/home/datascience/floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 256, 2: 128, 1: 64, 0: 32}\n",
      "Dataset Read\n",
      "['/home/datascience//floods/floods-r02.tfrecords', '/home/datascience//floods/floods-r03.tfrecords', '/home/datascience//floods/floods-r04.tfrecords', '/home/datascience//floods/floods-r05.tfrecords', '/home/datascience//floods/floods-r06.tfrecords', '/home/datascience//floods/floods-r07.tfrecords', '/home/datascience//floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 64, 2: 64, 1: 32, 0: 16}\n",
      "Dataset Read\n",
      "<BatchDataset element_spec=TensorSpec(shape=(None, 1, None, None), dtype=tf.uint8, name=None)>\n",
      "0\n",
      "Increase Resoltion from -1 to 256\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "256\n",
      "Changing optimizer\n",
      "False\n",
      "Changing optimizer\n",
      "False\n",
      "Finished changing resolution\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 22:14:48.406291: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8401\n",
      "2023-04-25 22:14:49.905924: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-04-25 22:14:50.204882: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: ptxas exited with non-zero error code 32512, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  27348714298452\n",
      "Average per batch was:  3.686407709121704\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "from train import train_cycle\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "train_cycle(datapath='/home/datascience/',outpath='./',init_res=256,max_res=256,change_model=True,minibatch_base=32,batch_size=32,profiling=True,use_tf32=False, use_precision='mixed_float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411f9326",
   "metadata": {},
   "source": [
    "## Mixed BFloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0090ea57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "2023-04-20 13:46:39.379308: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-20 13:46:40.228279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38214 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "2023-04-20 13:46:40.237752: I tensorflow/core/common_runtime/direct_session.cc:370] Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "\n",
      "True\n",
      "64\n",
      "2023-04-20 13:46:40.252888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38214 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.00035309791564941406 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  1952\n",
      "2023-04-20 13:46:49.211593: I tensorflow/compiler/xla/service/service.cc:171] XLA service 0x7fcc28017710 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-20 13:46:49.211877: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0\n",
      "2023-04-20 13:46:49.625801: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:57] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. Discriminator/Discriminator_base/dropout/dropout/random_uniform/RandomUniform\n",
      "2023-04-20 13:46:49.653543: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator assert_positive/assert_less/Assert/Assert\n",
      "2023-04-20 13:46:49.653691: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator assert_positive_1/assert_less/Assert/Assert\n",
      "2023-04-20 13:46:49.654431: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator assert_positive_2/assert_less/Assert/Assert\n",
      "2023-04-20 13:46:49.654554: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator assert_positive_3/assert_less/Assert/Assert\n",
      "2023-04-20 13:46:49.654675: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator assert_positive_4/assert_less/Assert/Assert\n",
      "2023-04-20 13:46:49.654825: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator assert_positive_5/assert_less/Assert/Assert\n",
      "2023-04-20 13:46:49.654966: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator assert_positive_6/assert_less/Assert/Assert\n",
      "2023-04-20 13:46:49.655089: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator assert_positive_7/assert_less/Assert/Assert\n",
      "2023-04-20 13:46:49.655209: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator assert_positive_8/assert_less/Assert/Assert\n",
      "2023-04-20 13:46:49.655332: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator assert_positive_9/assert_less/Assert/Assert\n",
      "2023-04-20 13:46:49.655358: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator assert_positive_10/assert_less/Assert/Assert\n",
      "2023-04-20 13:46:49.655380: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator assert_positive_11/assert_less/Assert/Assert\n",
      "2023-04-20 13:46:49.655407: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator assert_positive_12/assert_less/Assert/Assert\n",
      "2023-04-20 13:46:49.655430: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator assert_positive_13/assert_less/Assert/Assert\n",
      "2023-04-20 13:46:49.655452: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator assert_positive_14/assert_less/Assert/Assert\n",
      "2023-04-20 13:46:49.655474: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator assert_positive_15/assert_less/Assert/Assert\n",
      "2023-04-20 13:46:49.683835: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-20 13:46:53.080010: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8401\n",
      "2023-04-20 13:46:59.711618: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-04-20 13:46:59.796459: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: ptxas exited with non-zero error code 32512, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-04-20 13:46:59.902491: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-04-20 13:46:59.985543: W tensorflow/compiler/xla/service/gpu/buffer_comparator.cc:640] INTERNAL: ptxas exited with non-zero error code 32512, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Setting XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda  or modifying $PATH can be used to set the location of ptxas\n",
      "This message will only be logged once.\n",
      "2023-04-20 13:47:13.426072: W tensorflow/compiler/xla/service/gpu/nvptx_helper.cc:35] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "2023-04-20 13:47:13.426138: W tensorflow/compiler/xla/service/gpu/nvptx_helper.cc:36] Searched for CUDA in the following directories:\n",
      "2023-04-20 13:47:13.426150: W tensorflow/compiler/xla/service/gpu/nvptx_helper.cc:39]   ./cuda_sdk_lib\n",
      "2023-04-20 13:47:13.426159: W tensorflow/compiler/xla/service/gpu/nvptx_helper.cc:39]   /usr/local/cuda-11.2\n",
      "2023-04-20 13:47:13.426168: W tensorflow/compiler/xla/service/gpu/nvptx_helper.cc:39]   /usr/local/cuda\n",
      "2023-04-20 13:47:13.426177: W tensorflow/compiler/xla/service/gpu/nvptx_helper.cc:39]   .\n",
      "2023-04-20 13:47:13.426186: W tensorflow/compiler/xla/service/gpu/nvptx_helper.cc:41] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "2023-04-20 13:47:13.452617: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:329] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-04-20 13:47:13.603469: I tensorflow/compiler/jit/xla_compilation_cache.cc:399] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-04-20 13:47:13.619056: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at xla_ops.cc:248 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "Traceback (most recent call last):\n",
      "  File \"gan_main.py\", line 781, in <module>\n",
      "    main_gan()\n",
      "  File \"gan_main.py\", line 391, in main_gan\n",
      "    real_batch_loss, fake_batch_loss, gen_losses = distributed_train_step(\n",
      "  File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 54, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.InternalError: Graph execution error:\n",
      "\n",
      "Detected at node 'StatefulPartitionedCall' defined at (most recent call last):\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
      "      self._bootstrap_inner()\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "      self.run()\n",
      "Node: 'StatefulPartitionedCall'\n",
      "Detected at node 'StatefulPartitionedCall' defined at (most recent call last):\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
      "      self._bootstrap_inner()\n",
      "    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "      self.run()\n",
      "Node: 'StatefulPartitionedCall'\n",
      "2 root error(s) found.\n",
      "  (0) INTERNAL:  libdevice not found at ./libdevice.10.bc\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n",
      "\t [[StatefulPartitionedCall/_28]]\n",
      "  (1) INTERNAL:  libdevice not found at ./libdevice.10.bc\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n",
      "0 successful operations.\n",
      "0 derived errors ignored. [Op:__inference_distributed_train_step_18341]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "from train import train_cycle\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "train_cycle(datapath='/home/datascience/',outpath='./',init_res=256,max_res=256,change_model=True,minibatch_base=32,batch_size=32,profiling=True,use_tf32=False, use_precision='mixed_bfloat16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44df2a8",
   "metadata": {},
   "source": [
    "## Results Mixed BFloat16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0c3e55",
   "metadata": {},
   "source": [
    "# Batch Size tf32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a7cde1",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a025988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "/home/datascience/floods/\n",
      "/home/datascience/floods/\n",
      "True\n",
      "8\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of devices: 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "['/home/datascience/floods/floods-r02.tfrecords', '/home/datascience/floods/floods-r03.tfrecords', '/home/datascience/floods/floods-r04.tfrecords', '/home/datascience/floods/floods-r05.tfrecords', '/home/datascience/floods/floods-r06.tfrecords', '/home/datascience/floods/floods-r07.tfrecords', '/home/datascience/floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 64, 2: 32, 1: 16, 0: 8}\n",
      "Dataset Read\n",
      "['/home/datascience/floods/floods-r02.tfrecords', '/home/datascience/floods/floods-r03.tfrecords', '/home/datascience/floods/floods-r04.tfrecords', '/home/datascience/floods/floods-r05.tfrecords', '/home/datascience/floods/floods-r06.tfrecords', '/home/datascience/floods/floods-r07.tfrecords', '/home/datascience/floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 64, 2: 32, 1: 16, 0: 8}\n",
      "Dataset Read\n",
      "['/home/datascience//floods/floods-r02.tfrecords', '/home/datascience//floods/floods-r03.tfrecords', '/home/datascience//floods/floods-r04.tfrecords', '/home/datascience//floods/floods-r05.tfrecords', '/home/datascience//floods/floods-r06.tfrecords', '/home/datascience//floods/floods-r07.tfrecords', '/home/datascience//floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 64, 2: 64, 1: 32, 0: 16}\n",
      "Dataset Read\n",
      "<BatchDataset element_spec=TensorSpec(shape=(None, 1, None, None), dtype=tf.uint8, name=None)>\n",
      "0\n",
      "Increase Resoltion from -1 to 256\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "256\n",
      "Changing optimizer\n",
      "False\n",
      "Changing optimizer\n",
      "False\n",
      "Finished changing resolution\n",
      "Mini-batch size G 8\n",
      "lat_and_cond : Tensor(\"random_normal:0\", shape=(8, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 8\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 8\n",
      "lat_and_cond : Tensor(\"random_normal_2:0\", shape=(8, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 8\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 8\n",
      "lat_and_cond : Tensor(\"random_normal:0\", shape=(8, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 8\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 8\n",
      "lat_and_cond : Tensor(\"random_normal_2:0\", shape=(8, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 8\n",
      "real shape(None, 1, None, None)\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  6837281955836\n",
      "Average per batch was:  1.6898613929748536\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "from train import train_cycle\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "train_cycle(datapath='/home/datascience/',outpath='./',init_res=256,max_res=256,change_model=True,minibatch_base=32,batch_size=8,profiling=True,use_tf32=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58239015",
   "metadata": {},
   "source": [
    "17921"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd183545",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9839143a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "/home/datascience/floods/\n",
      "/home/datascience/floods/\n",
      "True\n",
      "16\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of devices: 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "['/home/datascience/floods/floods-r02.tfrecords', '/home/datascience/floods/floods-r03.tfrecords', '/home/datascience/floods/floods-r04.tfrecords', '/home/datascience/floods/floods-r05.tfrecords', '/home/datascience/floods/floods-r06.tfrecords', '/home/datascience/floods/floods-r07.tfrecords', '/home/datascience/floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 128, 2: 64, 1: 32, 0: 16}\n",
      "Dataset Read\n",
      "['/home/datascience/floods/floods-r02.tfrecords', '/home/datascience/floods/floods-r03.tfrecords', '/home/datascience/floods/floods-r04.tfrecords', '/home/datascience/floods/floods-r05.tfrecords', '/home/datascience/floods/floods-r06.tfrecords', '/home/datascience/floods/floods-r07.tfrecords', '/home/datascience/floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 128, 2: 64, 1: 32, 0: 16}\n",
      "Dataset Read\n",
      "['/home/datascience//floods/floods-r02.tfrecords', '/home/datascience//floods/floods-r03.tfrecords', '/home/datascience//floods/floods-r04.tfrecords', '/home/datascience//floods/floods-r05.tfrecords', '/home/datascience//floods/floods-r06.tfrecords', '/home/datascience//floods/floods-r07.tfrecords', '/home/datascience//floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 64, 2: 64, 1: 32, 0: 16}\n",
      "Dataset Read\n",
      "<BatchDataset element_spec=TensorSpec(shape=(None, 1, None, None), dtype=tf.uint8, name=None)>\n",
      "0\n",
      "Increase Resoltion from -1 to 256\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "256\n",
      "Changing optimizer\n",
      "False\n",
      "Changing optimizer\n",
      "False\n",
      "Finished changing resolution\n",
      "Mini-batch size G 16\n",
      "lat_and_cond : Tensor(\"random_normal:0\", shape=(16, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 16\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 16\n",
      "lat_and_cond : Tensor(\"random_normal_2:0\", shape=(16, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 16\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 16\n",
      "lat_and_cond : Tensor(\"random_normal:0\", shape=(16, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 16\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 16\n",
      "lat_and_cond : Tensor(\"random_normal_2:0\", shape=(16, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 16\n",
      "real shape(None, 1, None, None)\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  13674426066580\n",
      "Average per batch was:  2.9985208988189695\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "from train import train_cycle\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "train_cycle(datapath='/home/datascience/',outpath='./',init_res=256,max_res=256,change_model=True,minibatch_base=32,batch_size=16,profiling=True,use_tf32=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb07ffe9",
   "metadata": {},
   "source": [
    "17921 / 34305"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc8cc5a",
   "metadata": {},
   "source": [
    "## 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "260e3046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "/home/datascience/floods/\n",
      "/home/datascience/floods/\n",
      "True\n",
      "64\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of devices: 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "['/home/datascience/floods/floods-r02.tfrecords', '/home/datascience/floods/floods-r03.tfrecords', '/home/datascience/floods/floods-r04.tfrecords', '/home/datascience/floods/floods-r05.tfrecords', '/home/datascience/floods/floods-r06.tfrecords', '/home/datascience/floods/floods-r07.tfrecords', '/home/datascience/floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 512, 2: 256, 1: 128, 0: 64}\n",
      "Dataset Read\n",
      "['/home/datascience/floods/floods-r02.tfrecords', '/home/datascience/floods/floods-r03.tfrecords', '/home/datascience/floods/floods-r04.tfrecords', '/home/datascience/floods/floods-r05.tfrecords', '/home/datascience/floods/floods-r06.tfrecords', '/home/datascience/floods/floods-r07.tfrecords', '/home/datascience/floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 512, 2: 256, 1: 128, 0: 64}\n",
      "Dataset Read\n",
      "['/home/datascience//floods/floods-r02.tfrecords', '/home/datascience//floods/floods-r03.tfrecords', '/home/datascience//floods/floods-r04.tfrecords', '/home/datascience//floods/floods-r05.tfrecords', '/home/datascience//floods/floods-r06.tfrecords', '/home/datascience//floods/floods-r07.tfrecords', '/home/datascience//floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 64, 2: 64, 1: 32, 0: 16}\n",
      "Dataset Read\n",
      "<BatchDataset element_spec=TensorSpec(shape=(None, 1, None, None), dtype=tf.uint8, name=None)>\n",
      "0\n",
      "Increase Resoltion from -1 to 256\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "256\n",
      "Changing optimizer\n",
      "False\n",
      "Changing optimizer\n",
      "False\n",
      "Finished changing resolution\n",
      "Mini-batch size G 64\n",
      "lat_and_cond : Tensor(\"random_normal:0\", shape=(64, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 64\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 64\n",
      "lat_and_cond : Tensor(\"random_normal_2:0\", shape=(64, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 64\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 64\n",
      "lat_and_cond : Tensor(\"random_normal:0\", shape=(64, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 64\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 64\n",
      "lat_and_cond : Tensor(\"random_normal_2:0\", shape=(64, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 64\n",
      "real shape(None, 1, None, None)\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_5/256x256/Conv1_down/Conv2D_3' defined at (most recent call last):\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 890, in _bootstrap\n      self._bootstrap_inner()\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n      self.run()\n    File \"/home/datascience/myCProGan/train.py\", line 352, in training_step\n      disc_loss, global_loss, local_loss = loss.combined_Discriminator_loss(gen, disc, cvae, train_batch, batch_size, D_optimizer, lod_in=lod_in, training_set=None, labels=None, wgan_lambda = 10.0, wgan_epsilon = 0.001, wgan_target = 1.0, cond_weight = 1.0,  network_size=net_size, global_batch_size = global_batch_size)\n    File \"/home/datascience/myCProGan/loss.py\", line 570, in combined_Discriminator_loss\n      global_mixed_scores_out = fp32(combined_D.use_global_discriminator(global_mixed_images_out, lod_in))\n    File \"/home/datascience/myCProGan/networks2.py\", line 130, in use_global_discriminator\n      scores = self.global_discriminator([image, lod], training=training_flag)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/layers/convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/layers/convolutional.py\", line 233, in convolution_op\n      return tf.nn.convolution(\nNode: 'model_5/256x256/Conv1_down/Conv2D_3'\nDetected at node 'model_5/256x256/Conv1_down/Conv2D_3' defined at (most recent call last):\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 890, in _bootstrap\n      self._bootstrap_inner()\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n      self.run()\n    File \"/home/datascience/myCProGan/train.py\", line 352, in training_step\n      disc_loss, global_loss, local_loss = loss.combined_Discriminator_loss(gen, disc, cvae, train_batch, batch_size, D_optimizer, lod_in=lod_in, training_set=None, labels=None, wgan_lambda = 10.0, wgan_epsilon = 0.001, wgan_target = 1.0, cond_weight = 1.0,  network_size=net_size, global_batch_size = global_batch_size)\n    File \"/home/datascience/myCProGan/loss.py\", line 570, in combined_Discriminator_loss\n      global_mixed_scores_out = fp32(combined_D.use_global_discriminator(global_mixed_images_out, lod_in))\n    File \"/home/datascience/myCProGan/networks2.py\", line 130, in use_global_discriminator\n      scores = self.global_discriminator([image, lod], training=training_flag)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/layers/convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/layers/convolutional.py\", line 233, in convolution_op\n      return tf.nn.convolution(\nNode: 'model_5/256x256/Conv1_down/Conv2D_3'\n2 root error(s) found.\n  (0) UNKNOWN:  CUDNN failed to allocate the scratch space for the runner or to find a working no-scratch runner.\n\t [[{{node model_5/256x256/Conv1_down/Conv2D_3}}]]\n\t [[Identity_11/_96]]\n  (1) UNKNOWN:  CUDNN failed to allocate the scratch space for the runner or to find a working no-scratch runner.\n\t [[{{node model_5/256x256/Conv1_down/Conv2D_3}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_training_step_tf_fuction_256_41858]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_47083/2320120676.py\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TF_CPP_MIN_LOG_LEVEL'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Num GPUs Available: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/home/datascience/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit_res\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_res\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchange_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mminibatch_base\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprofiling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_tf32\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/myCProGan/train.py\u001b[0m in \u001b[0;36mtrain_cycle\u001b[0;34m(multi_node, index, use_gs, datapath, outpath, init_res, max_res, change_model, lod_training_kimg, lod_transition_kimg, minibatch_base, total_kimg, minibatch_repeats, D_repeats, batch_size, load, use_gpus, profiling, use_tf32, use_precision)\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_test_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_test_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_test_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_test_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_step_tf_fuction_128\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_iter_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_iter_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlod_in_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mresolution\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m                 \u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_test_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_test_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_test_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_test_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_step_tf_fuction_256\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_iter_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_iter_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlod_in_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m             \u001b[0;31m#print(lossval.numpy())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node 'model_5/256x256/Conv1_down/Conv2D_3' defined at (most recent call last):\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 890, in _bootstrap\n      self._bootstrap_inner()\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n      self.run()\n    File \"/home/datascience/myCProGan/train.py\", line 352, in training_step\n      disc_loss, global_loss, local_loss = loss.combined_Discriminator_loss(gen, disc, cvae, train_batch, batch_size, D_optimizer, lod_in=lod_in, training_set=None, labels=None, wgan_lambda = 10.0, wgan_epsilon = 0.001, wgan_target = 1.0, cond_weight = 1.0,  network_size=net_size, global_batch_size = global_batch_size)\n    File \"/home/datascience/myCProGan/loss.py\", line 570, in combined_Discriminator_loss\n      global_mixed_scores_out = fp32(combined_D.use_global_discriminator(global_mixed_images_out, lod_in))\n    File \"/home/datascience/myCProGan/networks2.py\", line 130, in use_global_discriminator\n      scores = self.global_discriminator([image, lod], training=training_flag)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/layers/convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/layers/convolutional.py\", line 233, in convolution_op\n      return tf.nn.convolution(\nNode: 'model_5/256x256/Conv1_down/Conv2D_3'\nDetected at node 'model_5/256x256/Conv1_down/Conv2D_3' defined at (most recent call last):\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 890, in _bootstrap\n      self._bootstrap_inner()\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n      self.run()\n    File \"/home/datascience/myCProGan/train.py\", line 352, in training_step\n      disc_loss, global_loss, local_loss = loss.combined_Discriminator_loss(gen, disc, cvae, train_batch, batch_size, D_optimizer, lod_in=lod_in, training_set=None, labels=None, wgan_lambda = 10.0, wgan_epsilon = 0.001, wgan_target = 1.0, cond_weight = 1.0,  network_size=net_size, global_batch_size = global_batch_size)\n    File \"/home/datascience/myCProGan/loss.py\", line 570, in combined_Discriminator_loss\n      global_mixed_scores_out = fp32(combined_D.use_global_discriminator(global_mixed_images_out, lod_in))\n    File \"/home/datascience/myCProGan/networks2.py\", line 130, in use_global_discriminator\n      scores = self.global_discriminator([image, lod], training=training_flag)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/layers/convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/layers/convolutional.py\", line 233, in convolution_op\n      return tf.nn.convolution(\nNode: 'model_5/256x256/Conv1_down/Conv2D_3'\n2 root error(s) found.\n  (0) UNKNOWN:  CUDNN failed to allocate the scratch space for the runner or to find a working no-scratch runner.\n\t [[{{node model_5/256x256/Conv1_down/Conv2D_3}}]]\n\t [[Identity_11/_96]]\n  (1) UNKNOWN:  CUDNN failed to allocate the scratch space for the runner or to find a working no-scratch runner.\n\t [[{{node model_5/256x256/Conv1_down/Conv2D_3}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_training_step_tf_fuction_256_41858]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "from train import train_cycle\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "train_cycle(datapath='/home/datascience/',outpath='./',init_res=256,max_res=256,change_model=True,minibatch_base=64,batch_size=64,profiling=True,use_tf32=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5110783c",
   "metadata": {},
   "source": [
    "34305"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d35db3",
   "metadata": {},
   "source": [
    "# Batch Size float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1ae9aa",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4566dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "/home/datascience/floods/\n",
      "/home/datascience/floods/\n",
      "False\n",
      "8\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of devices: 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "['/home/datascience/floods/floods-r02.tfrecords', '/home/datascience/floods/floods-r03.tfrecords', '/home/datascience/floods/floods-r04.tfrecords', '/home/datascience/floods/floods-r05.tfrecords', '/home/datascience/floods/floods-r06.tfrecords', '/home/datascience/floods/floods-r07.tfrecords', '/home/datascience/floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 64, 2: 32, 1: 16, 0: 8}\n",
      "Dataset Read\n",
      "['/home/datascience/floods/floods-r02.tfrecords', '/home/datascience/floods/floods-r03.tfrecords', '/home/datascience/floods/floods-r04.tfrecords', '/home/datascience/floods/floods-r05.tfrecords', '/home/datascience/floods/floods-r06.tfrecords', '/home/datascience/floods/floods-r07.tfrecords', '/home/datascience/floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 64, 2: 32, 1: 16, 0: 8}\n",
      "Dataset Read\n",
      "['/home/datascience//floods/floods-r02.tfrecords', '/home/datascience//floods/floods-r03.tfrecords', '/home/datascience//floods/floods-r04.tfrecords', '/home/datascience//floods/floods-r05.tfrecords', '/home/datascience//floods/floods-r06.tfrecords', '/home/datascience//floods/floods-r07.tfrecords', '/home/datascience//floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 64, 2: 64, 1: 32, 0: 16}\n",
      "Dataset Read\n",
      "<BatchDataset element_spec=TensorSpec(shape=(None, 1, None, None), dtype=tf.uint8, name=None)>\n",
      "0\n",
      "Increase Resoltion from -1 to 256\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "256\n",
      "Changing optimizer\n",
      "False\n",
      "Changing optimizer\n",
      "False\n",
      "Finished changing resolution\n",
      "Mini-batch size G 8\n",
      "lat_and_cond : Tensor(\"random_normal:0\", shape=(8, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 8\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 8\n",
      "lat_and_cond : Tensor(\"random_normal_2:0\", shape=(8, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 8\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 8\n",
      "lat_and_cond : Tensor(\"random_normal:0\", shape=(8, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 8\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 8\n",
      "lat_and_cond : Tensor(\"random_normal_2:0\", shape=(8, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 8\n",
      "real shape(None, 1, None, None)\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  6837281955836\n",
      "Average per batch was:  2.9468667030334474\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "from train import train_cycle\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "train_cycle(datapath='/home/datascience/',outpath='./',init_res=256,max_res=256,change_model=True,minibatch_base=64,batch_size=8,profiling=True,use_tf32=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d794d8b",
   "metadata": {},
   "source": [
    "17921"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb51f332",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eb13ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "/home/datascience/floods/\n",
      "/home/datascience/floods/\n",
      "False\n",
      "16\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of devices: 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "['/home/datascience/floods/floods-r02.tfrecords', '/home/datascience/floods/floods-r03.tfrecords', '/home/datascience/floods/floods-r04.tfrecords', '/home/datascience/floods/floods-r05.tfrecords', '/home/datascience/floods/floods-r06.tfrecords', '/home/datascience/floods/floods-r07.tfrecords', '/home/datascience/floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 128, 2: 64, 1: 32, 0: 16}\n",
      "Dataset Read\n",
      "['/home/datascience/floods/floods-r02.tfrecords', '/home/datascience/floods/floods-r03.tfrecords', '/home/datascience/floods/floods-r04.tfrecords', '/home/datascience/floods/floods-r05.tfrecords', '/home/datascience/floods/floods-r06.tfrecords', '/home/datascience/floods/floods-r07.tfrecords', '/home/datascience/floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 128, 2: 64, 1: 32, 0: 16}\n",
      "Dataset Read\n",
      "['/home/datascience//floods/floods-r02.tfrecords', '/home/datascience//floods/floods-r03.tfrecords', '/home/datascience//floods/floods-r04.tfrecords', '/home/datascience//floods/floods-r05.tfrecords', '/home/datascience//floods/floods-r06.tfrecords', '/home/datascience//floods/floods-r07.tfrecords', '/home/datascience//floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 64, 2: 64, 1: 32, 0: 16}\n",
      "Dataset Read\n",
      "<BatchDataset element_spec=TensorSpec(shape=(None, 1, None, None), dtype=tf.uint8, name=None)>\n",
      "0\n",
      "Increase Resoltion from -1 to 256\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "256\n",
      "Changing optimizer\n",
      "False\n",
      "Changing optimizer\n",
      "False\n",
      "Finished changing resolution\n",
      "Mini-batch size G 16\n",
      "lat_and_cond : Tensor(\"random_normal:0\", shape=(16, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 16\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 16\n",
      "lat_and_cond : Tensor(\"random_normal_2:0\", shape=(16, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 16\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 16\n",
      "lat_and_cond : Tensor(\"random_normal:0\", shape=(16, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 16\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 16\n",
      "lat_and_cond : Tensor(\"random_normal_2:0\", shape=(16, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 1\n",
      "Mini-batch size D 16\n",
      "real shape(None, 1, None, None)\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  13674426066580\n",
      "Average per batch was:  4.671027183532715\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "from train import train_cycle\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "train_cycle(datapath='/home/datascience/',outpath='./',init_res=256,max_res=256,change_model=True,minibatch_base=64,batch_size=16,profiling=True,use_tf32=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675fff3a",
   "metadata": {},
   "source": [
    "17921"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf90f5",
   "metadata": {},
   "source": [
    "## 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4ae9699f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "False\n",
      "256\n",
      "Number of devices: 1\n",
      "Searching in : /home/datascience/tfrecordsprepro/*.tfrecords\n",
      "Found 28 files. \n",
      "Initialization time is 0.0003867149353027344 seconds\n",
      "Loading Data\n",
      "Epoch 1 of 60\n",
      "Number of Batches:  488\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  8606716502120\n",
      "Average per batch was:  5.5624189376831055\n",
      "Time taken by batch 6  was 5.854866981506348 seconds.\n",
      "Time taken by epoch0 was 93.62191557884216 seconds.\n",
      "\n",
      "Testing for epoch 0:\n",
      "(256, 256)\n",
      "FLOP =  6049885346822\n",
      "Average per batch was:  1.0930707454681396\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "from train import train_cycle\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "train_cycle(datapath='/home/datascience/',outpath='./',init_res=256,max_res=256,change_model=True,minibatch_base=64,batch_size=64,profiling=True,use_tf32=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83707cf0",
   "metadata": {},
   "source": [
    "34305"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d338b7",
   "metadata": {},
   "source": [
    "# Number of GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f41fe19",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d48858ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/datascience/floods/\n",
      "/home/datascience/floods/\n",
      "True\n",
      "64\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "['/home/datascience/floods/floods-r02.tfrecords', '/home/datascience/floods/floods-r03.tfrecords', '/home/datascience/floods/floods-r04.tfrecords', '/home/datascience/floods/floods-r05.tfrecords', '/home/datascience/floods/floods-r06.tfrecords', '/home/datascience/floods/floods-r07.tfrecords', '/home/datascience/floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 512, 2: 256, 1: 128, 0: 64}\n",
      "Dataset Read\n",
      "['/home/datascience/floods/floods-r02.tfrecords', '/home/datascience/floods/floods-r03.tfrecords', '/home/datascience/floods/floods-r04.tfrecords', '/home/datascience/floods/floods-r05.tfrecords', '/home/datascience/floods/floods-r06.tfrecords', '/home/datascience/floods/floods-r07.tfrecords', '/home/datascience/floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 512, 2: 256, 1: 128, 0: 64}\n",
      "Dataset Read\n",
      "['/home/datascience//floods/floods-r02.tfrecords', '/home/datascience//floods/floods-r03.tfrecords', '/home/datascience//floods/floods-r04.tfrecords', '/home/datascience//floods/floods-r05.tfrecords', '/home/datascience//floods/floods-r06.tfrecords', '/home/datascience//floods/floods-r07.tfrecords', '/home/datascience//floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 64, 2: 64, 1: 32, 0: 16}\n",
      "Dataset Read\n",
      "<BatchDataset element_spec=TensorSpec(shape=(None, 1, None, None), dtype=tf.uint8, name=None)>\n",
      "0\n",
      "Increase Resoltion from -1 to 256\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "256\n",
      "Changing optimizer\n",
      "False\n",
      "Changing optimizer\n",
      "False\n",
      "Finished changing resolution\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_1/random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "INFO:tensorflow:batch_all_reduce: 35 all-reduces with algorithm = nccl, num_packs = 1\n",
      "N GPUS: 2\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "N GPUS: 2\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "INFO:tensorflow:batch_all_reduce: 82 all-reduces with algorithm = nccl, num_packs = 1\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 2\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_1/random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "N GPUS: 2\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_1/random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "INFO:tensorflow:batch_all_reduce: 35 all-reduces with algorithm = nccl, num_packs = 1\n",
      "N GPUS: 2\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "N GPUS: 2\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "INFO:tensorflow:batch_all_reduce: 82 all-reduces with algorithm = nccl, num_packs = 1\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 2\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_1/random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "N GPUS: 2\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  54697428596867\n",
      "Average per batch was:  5.6762346744537355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "from train import train_cycle\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "train_cycle(datapath='/home/datascience/',outpath='./',init_res=256,max_res=256,change_model=True,minibatch_base=64,batch_size=64,profiling=True,use_tf32=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1f0ecf",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5a74435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/datascience/floods/\n",
      "/home/datascience/floods/\n",
      "True\n",
      "128\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Number of devices: 4\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "['/home/datascience/floods/floods-r02.tfrecords', '/home/datascience/floods/floods-r03.tfrecords', '/home/datascience/floods/floods-r04.tfrecords', '/home/datascience/floods/floods-r05.tfrecords', '/home/datascience/floods/floods-r06.tfrecords', '/home/datascience/floods/floods-r07.tfrecords', '/home/datascience/floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 1024, 2: 512, 1: 256, 0: 128}\n",
      "Dataset Read\n",
      "['/home/datascience/floods/floods-r02.tfrecords', '/home/datascience/floods/floods-r03.tfrecords', '/home/datascience/floods/floods-r04.tfrecords', '/home/datascience/floods/floods-r05.tfrecords', '/home/datascience/floods/floods-r06.tfrecords', '/home/datascience/floods/floods-r07.tfrecords', '/home/datascience/floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 1024, 2: 512, 1: 256, 0: 128}\n",
      "Dataset Read\n",
      "['/home/datascience//floods/floods-r02.tfrecords', '/home/datascience//floods/floods-r03.tfrecords', '/home/datascience//floods/floods-r04.tfrecords', '/home/datascience//floods/floods-r05.tfrecords', '/home/datascience//floods/floods-r06.tfrecords', '/home/datascience//floods/floods-r07.tfrecords', '/home/datascience//floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 64, 2: 64, 1: 32, 0: 16}\n",
      "Dataset Read\n",
      "<BatchDataset element_spec=TensorSpec(shape=(None, 1, None, None), dtype=tf.uint8, name=None)>\n",
      "0\n",
      "Increase Resoltion from -1 to 256\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "256\n",
      "Changing optimizer\n",
      "False\n",
      "Changing optimizer\n",
      "False\n",
      "Finished changing resolution\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_1/random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_2/random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:2)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_3/random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:3)\n",
      "INFO:tensorflow:batch_all_reduce: 35 all-reduces with algorithm = nccl, num_packs = 1\n",
      "N GPUS: 4\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "N GPUS: 4\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "N GPUS: 4\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "N GPUS: 4\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "INFO:tensorflow:batch_all_reduce: 82 all-reduces with algorithm = nccl, num_packs = 1\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 4\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_1/random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "N GPUS: 4\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_2/random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:2)\n",
      "N GPUS: 4\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_3/random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:3)\n",
      "N GPUS: 4\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_1/random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_2/random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:2)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_3/random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:3)\n",
      "INFO:tensorflow:batch_all_reduce: 35 all-reduces with algorithm = nccl, num_packs = 1\n",
      "N GPUS: 4\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "N GPUS: 4\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "N GPUS: 4\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "N GPUS: 4\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "INFO:tensorflow:batch_all_reduce: 82 all-reduces with algorithm = nccl, num_packs = 1\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 4\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_1/random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "N GPUS: 4\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_2/random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:2)\n",
      "N GPUS: 4\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_3/random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:3)\n",
      "N GPUS: 4\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  109394857193825\n",
      "Average per batch was:  5.809936809539795\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "from train import train_cycle\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "train_cycle(datapath='/home/datascience/',outpath='./',init_res=256,max_res=256,change_model=True,minibatch_base=64,batch_size=128,profiling=True,use_tf32=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d77506",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ed739a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/datascience/floods/\n",
      "/home/datascience/floods/\n",
      "True\n",
      "256\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n",
      "Number of devices: 8\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "['/home/datascience/floods/floods-r02.tfrecords', '/home/datascience/floods/floods-r03.tfrecords', '/home/datascience/floods/floods-r04.tfrecords', '/home/datascience/floods/floods-r05.tfrecords', '/home/datascience/floods/floods-r06.tfrecords', '/home/datascience/floods/floods-r07.tfrecords', '/home/datascience/floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 2048, 2: 1024, 1: 512, 0: 256}\n",
      "Dataset Read\n",
      "['/home/datascience/floods/floods-r02.tfrecords', '/home/datascience/floods/floods-r03.tfrecords', '/home/datascience/floods/floods-r04.tfrecords', '/home/datascience/floods/floods-r05.tfrecords', '/home/datascience/floods/floods-r06.tfrecords', '/home/datascience/floods/floods-r07.tfrecords', '/home/datascience/floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 2048, 2: 1024, 1: 512, 0: 256}\n",
      "Dataset Read\n",
      "['/home/datascience//floods/floods-r02.tfrecords', '/home/datascience//floods/floods-r03.tfrecords', '/home/datascience//floods/floods-r04.tfrecords', '/home/datascience//floods/floods-r05.tfrecords', '/home/datascience//floods/floods-r06.tfrecords', '/home/datascience//floods/floods-r07.tfrecords', '/home/datascience//floods/floods-r08.tfrecords']\n",
      "[(1, 4, 4), (1, 8, 8), (1, 16, 16), (1, 32, 32), (1, 64, 64), (1, 128, 128), (1, 256, 256)]\n",
      "[6, 5, 4, 3, 2, 1, 0]\n",
      "{6: 1024, 5: 512, 4: 256, 3: 64, 2: 64, 1: 32, 0: 16}\n",
      "Dataset Read\n",
      "<BatchDataset element_spec=TensorSpec(shape=(None, 1, None, None), dtype=tf.uint8, name=None)>\n",
      "0\n",
      "Increase Resoltion from -1 to 256\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "256\n",
      "Changing optimizer\n",
      "False\n",
      "Changing optimizer\n",
      "False\n",
      "Finished changing resolution\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_1/random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_2/random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:2)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_3/random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:3)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_4/random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:4)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_5/random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:5)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_6/random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:6)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_7/random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:7)\n",
      "INFO:tensorflow:batch_all_reduce: 35 all-reduces with algorithm = nccl, num_packs = 1\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "INFO:tensorflow:batch_all_reduce: 82 all-reduces with algorithm = nccl, num_packs = 1\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_1/random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_2/random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:2)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_3/random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:3)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_4/random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:4)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_5/random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:5)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_6/random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:6)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_7/random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:7)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_1/random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_2/random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:2)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_3/random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:3)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_4/random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:4)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_5/random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:5)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_6/random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:6)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_7/random_normal:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:7)\n",
      "INFO:tensorflow:batch_all_reduce: 35 all-reduces with algorithm = nccl, num_packs = 1\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "INFO:tensorflow:batch_all_reduce: 82 all-reduces with algorithm = nccl, num_packs = 1\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_1/random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_2/random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:2)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_3/random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:3)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_4/random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:4)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_5/random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:5)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_6/random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:6)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "Mini-batch size G 32\n",
      "lat_and_cond : Tensor(\"replica_7/random_normal_2:0\", shape=(32, 2048), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:7)\n",
      "N GPUS: 8\n",
      "Mini-batch size D 32\n",
      "real shape(None, 1, None, None)\n",
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOP =  218789714388125\n",
      "Average per batch was:  5.8523331642150875\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os\n",
    "from train import train_cycle\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3,4,5,6,7\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "train_cycle(datapath='/home/datascience/',outpath='./',init_res=256,max_res=256,change_model=True,minibatch_base=64,batch_size=256,profiling=True,use_tf32=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43385eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: gan_main.py [-h] [--multi_node MULTI_NODE]\n",
      "                   [--workers WORKERS [WORKERS ...]] [--index INDEX]\n",
      "                   [--use_gs USE_GS] [--datapath DATAPATH] [--outpath OUTPATH]\n",
      "                   [--nbepochs NBEPOCHS] [--batchsize BATCHSIZE]\n",
      "                   [--use_gpus USE_GPUS]\n",
      "                   [--GLOBAL_BATCH_SIZE GLOBAL_BATCH_SIZE]\n",
      "                   [--nb_epochs NB_EPOCHS] [--batch_size BATCH_SIZE]\n",
      "                   [--latent_size LATENT_SIZE] [--verbose VERBOSE]\n",
      "                   [--nEvents NEVENTS] [--ascale ASCALE] [--yscale YSCALE]\n",
      "                   [--xscale XSCALE] [--xpower XPOWER] [--angscale ANGSCALE]\n",
      "                   [--analyse ANALYSE] [--dformat DFORMAT] [--thresh THRESH]\n",
      "                   [--angtype ANGTYPE] [--particle PARTICLE] [--warm WARM]\n",
      "                   [--lr LR] [--events_per_file EVENTS_PER_FILE] [--name NAME]\n",
      "                   [--g_weights G_WEIGHTS] [--d_weights D_WEIGHTS]\n",
      "                   [--tlab TLAB] [--profiling] [--use_tf32]\n",
      "                   [--use_precision USE_PRECISION]\n",
      "\n",
      "3D GAN Params\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --multi_node MULTI_NODE\n",
      "  --workers WORKERS [WORKERS ...]\n",
      "  --index INDEX\n",
      "  --use_gs USE_GS\n",
      "  --datapath DATAPATH   Data path\n",
      "  --outpath OUTPATH     training output\n",
      "  --nbepochs NBEPOCHS   Number of epochs to train for.\n",
      "  --batchsize BATCHSIZE\n",
      "                        batch size per update\n",
      "  --use_gpus USE_GPUS   Use gpus for training\n",
      "  --GLOBAL_BATCH_SIZE GLOBAL_BATCH_SIZE\n",
      "  --nb_epochs NB_EPOCHS\n",
      "                        Total Epochs\n",
      "  --batch_size BATCH_SIZE\n",
      "  --latent_size LATENT_SIZE\n",
      "                        latent vector size\n",
      "  --verbose VERBOSE\n",
      "  --nEvents NEVENTS     maximum number of events used in training\n",
      "  --ascale ASCALE       angle scale\n",
      "  --yscale YSCALE       scaling energy\n",
      "  --xscale XSCALE\n",
      "  --xpower XPOWER\n",
      "  --angscale ANGSCALE\n",
      "  --analyse ANALYSE     if analysing\n",
      "  --dformat DFORMAT\n",
      "  --thresh THRESH       threshold for data\n",
      "  --angtype ANGTYPE\n",
      "  --particle PARTICLE\n",
      "  --warm WARM\n",
      "  --lr LR\n",
      "  --events_per_file EVENTS_PER_FILE\n",
      "  --name NAME\n",
      "  --g_weights G_WEIGHTS\n",
      "  --d_weights D_WEIGHTS\n",
      "  --tlab TLAB\n",
      "  --profiling\n",
      "  --use_tf32\n",
      "  --use_precision USE_PRECISION\n"
     ]
    }
   ],
   "source": [
    "!python gan_main.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6d67bdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bfloat16\n",
      "float32\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.enable_tensor_float_32_execution(False)\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "\n",
    "layer = tf.keras.layers.Conv2D(filters=4, kernel_size=2)\n",
    "print(layer.compute_dtype)\n",
    "print(layer.variable_dtype)\n",
    "\n",
    "print(tf.config.experimental.tensor_float_32_execution_enabled())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c45dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "  data = './data/penn'\n",
    "  model = 'LSTM'\n",
    "  emsize = 200\n",
    "  nhid = 200\n",
    "\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "05904dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304.44\n",
      "75.02\n",
      "224.8809090909091\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home/datascience/gpu_stats/tf32_bs96.csv', header=None)\n",
    "\n",
    "#print(df)\n",
    "#power.draw [W]  utilization.gpu [%]\n",
    "\n",
    "power_values = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if index > 0:\n",
    "        value = int(row[1][:-2])\n",
    "        if value >= 90:\n",
    "            power_values.append(float(row[0][:-2]))\n",
    "            \n",
    "print(max(power_values))\n",
    "print(min(power_values))\n",
    "print(sum(power_values)/len(power_values))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2461d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow28_p38_gpu_v1]",
   "language": "python",
   "name": "conda-env-tensorflow28_p38_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
